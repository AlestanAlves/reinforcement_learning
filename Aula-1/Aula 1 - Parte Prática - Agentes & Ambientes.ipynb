{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aula 1 - Parte Prática - Agentes & Ambientes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introdução\n",
    "\n",
    "Nesse primeiro notebook iremos aprender sobre a API do [OpenAI Gym](http://gym.openai.com/) e começaremos a implementar alguns componentes de um agente de RL.\n",
    "Ao final dessa parte prática teremos implementado o **ciclo de interação Agente-Ambiente** que nos permitirá futuramente treinar o agente e avaliar sua performance.\n",
    "\n",
    "<img src=\"img/agent-env-loop.png\" alt=\"Agent-Env Loop\" style=\"width: 450px;\"/>\n",
    "\n",
    "\n",
    "### Objetivos:\n",
    "\n",
    "- Relacionar os conceitos de Processos de Decisão Markovianos (MDPs) com os atributos e métodos de um ambiente definido com o OpenAI Gym;\n",
    "- Familiarizar-se com os componentes básicos de um agente de RL;\n",
    "- Implementar o ciclo de interação Agente-Ambiente; e\n",
    "- Implementar um primeiro agente aleatório e avaliar sua performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports\n",
    "\n",
    "> **Atenção:** não se esqueça de executar todos os `imports` necessários antes prosseguir com o tutorial. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"1001\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  var JS_MIME_TYPE = 'application/javascript';\n",
       "  var HTML_MIME_TYPE = 'text/html';\n",
       "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    var script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    var cell = handle.cell;\n",
       "\n",
       "    var id = cell.output_area._bokeh_element_id;\n",
       "    var server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null && id in Bokeh.index) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            var id = msg.content.text.trim();\n",
       "            if (id in Bokeh.index) {\n",
       "              Bokeh.index[id].model.document.clear();\n",
       "              delete Bokeh.index[id];\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    var output_area = handle.output_area;\n",
       "    var output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      var bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      var script_attrs = bk_div.children[0].attributes;\n",
       "      for (var i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      var toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    var el = document.getElementById(\"1001\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = css_urls.length + js_urls.length;\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "\n",
       "    function on_error() {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    for (var i = 0; i < css_urls.length; i++) {\n",
       "      var url = css_urls[i];\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }\n",
       "\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "  };var element = document.getElementById(\"1001\");\n",
       "  if (element == null) {\n",
       "    console.error(\"Bokeh: ERROR: autoload.js configured with elementid '1001' but no matching script tag was found. \")\n",
       "    return false;\n",
       "  }\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  \n",
       "  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-1.4.0.min.js\"];\n",
       "  var css_urls = [];\n",
       "  \n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    function(Bokeh) {\n",
       "    \n",
       "    \n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if (root.Bokeh !== undefined || force === true) {\n",
       "      \n",
       "    for (var i = 0; i < inline_js.length; i++) {\n",
       "      inline_js[i].call(root, root.Bokeh);\n",
       "    }\n",
       "    if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"1001\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(css_urls, js_urls, function() {\n",
       "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(\"1001\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };var element = document.getElementById(\"1001\");\n  if (element == null) {\n    console.error(\"Bokeh: ERROR: autoload.js configured with elementid '1001' but no matching script tag was found. \")\n    return false;\n  }\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  \n  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-1.4.0.min.js\"];\n  var css_urls = [];\n  \n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    function(Bokeh) {\n    \n    \n    }\n  ];\n\n  function run_inline_js() {\n    \n    if (root.Bokeh !== undefined || force === true) {\n      \n    for (var i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n    if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(\"1001\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import abc\n",
    "import random\n",
    "\n",
    "import gym\n",
    "\n",
    "from utils.viz import plot_action_distribution, plot_episode_total_rewards"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Ambientes no OpenAI Gym\n",
    "\n",
    "Um ambiente no OpenAI Gym encapsula um simulador com o qual um agente pode interagir. Nesse simulador, a cada instante $t$ o agente deve escolhar uma ação $\\mathbf{a}_t \\in \\mathcal{A}$ a ser executada. Ao receber essa ação, o ambiente tem seu estado $\\mathbf{s}_t \\in \\mathcal{S}$ alterado para outro estado $\\mathbf{s}_{t+1} \\in \\mathcal{S}$ e devolve para o agente uma observação (que pode ou não corresponder ao estado) e uma recompensa/punição $r_{t+1} \\in \\mathbb{R}$.\n",
    "\n",
    "O pacote Gym conta com inúmeros [ambientes pré-programados](http://gym.openai.com/envs/) e prontos para serem usados para testar algoritmos de RL. Nessa parte prática, começaremos a explorar alguns ambientes mais simples a fim de nos familiarizarmos com os principais conceitos de modelagem da biblioteca Gym."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para carregar um ambiente disponível no Gym basta chamar a função `gym.make` passando como argumento o identificador do ambiente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"MountainCar-v0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Atenção**: antes de usar um ambiente do Gym com o qual você não está familiarizado pode ser útil ler a sua documentação online.\n",
    "> Para o `MountainCar-v0` acesse o link [http://gym.openai.com/envs/MountainCar-v0/](http://gym.openai.com/envs/MountainCar-v0/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Informações adicionais sobre o ambiente/simulador podem ser obtidas accessando o atributo `env.spec`. Embora não seja obrigatório, muitos ambientes do OpenAI Gym definem  metadados importantes relacionados à tarefa de RL. Em particular, `env.spec.max_episode_steps` define o número máximo de passos de decisão que um agente pode tomar em um episódio (i.e., o tamanho máximo de uma trajetória) e `env.spec.reward_threshold` define o valor mínimo de retorno (i.e., recompensa total) de um episódio para o qual a tarefa é considerada resolvida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"MAX_EPISODE_STEPS = {env.spec.max_episode_steps}\")\n",
    "print(f\"REWARD THRESHOLD = {env.spec.reward_threshold}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Espaço de estados e ações\n",
    "\n",
    "Todo agente de RL deve conhecer quais ações pode tomar no ambiente e também quais as características das variáveis de observações que aquele ambiente lhe disponibiliza. Para acessar o espaço de estados e ações, um ambiente do gym disponibiliza os atributos `env.observation_space` e `env.action_space`, respectivamente.\n",
    "\n",
    "Note que essas informações serão importantes futuramente na definição das entradas e saídas das redes neurais artificiais que utilizaremos para representar a política $\\pi_\\theta$ do agente e também na criação de outros modelos.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todo `observation_space` tem associado seu tipo numérico (e.g., int, float,...) e as dimensões de uma observação. Além disso, é possível saber se o valor das variáveis observação são limitadas ou não, e se forem limitadas qual o valor mínimo e máximo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_space = env.observation_space\n",
    "\n",
    "print(obs_space.dtype)\n",
    "print(obs_space.shape)\n",
    "print(obs_space.bounded_above, obs_space.low)\n",
    "print(obs_space.bounded_below, obs_space.high)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para o `MountainCar-v0` note que uma observação correponde a um vetor de números reais de tamanho 2 (i.e., um par de valores em ponto flutuante). Note que a primeira componente do vetor é limitada entre -1.2 e 0.6, e a segunda componente entre -0.07 e 0.07. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analogamente, todo `action_space` tem associado seu tipo numérico e as dimensões de uma ação:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_space = env.action_space\n",
    "\n",
    "print(action_space.dtype)\n",
    "print(action_space.shape)\n",
    "print(action_space.n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note que para o `MountainCar-v0` o agente deverá escolher ações discretas (i.e., representadas por números inteiros). Observe também que o `shape==()` indica que uma ação é dada por um único escalar (e não um vetor como no caso do `observation_space`. Para acessar o número de possíveis valores da ação basta acessar o atributo `action_space.n`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Atenção**: em algumas situações pode ser interessante ter acesso à amostras de observações e ações. Você pode usar os métodos `env.observation_space.sample()` e `env.action_space.sample()` para gerar aleatoriamente observações e ações direto do ambiente `env`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_samples = [env.observation_space.sample() for _ in range(3)]\n",
    "print(obs_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_samples = [env.action_space.sample() for _ in range(5)]\n",
    "print(action_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Interface do Gym: métodos reset, step, render e close\n",
    "\n",
    "Um objeto `env` do Gym fornece 4 métodos principais para interagir com o simulador: \n",
    "1. `reset` permite re-inicialiar o simulador para um de seus estados iniciais;\n",
    "2. `step` se encarrega de executar uma ação no ambiente;\n",
    "3. `render` visualiza graficamente o estado do agente; e\n",
    "4. `close` libera recursos utilizados na simulação (por exemplo fecha a janela de visualização)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    obs = env.reset()\n",
    "    print(f\"obs {i} = {obs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note que a observação do estado inicial muda conforme o método `.reset()` é chamado. Isso se deve ao fato de que o estado inicial é definido como uma variável aleatória regida por uma distribuição inicial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = env.reset()\n",
    "\n",
    "for i in range(5):\n",
    "    action = env.action_space.sample()\n",
    "    obs, reward, done, info = env.step(action)\n",
    "    print(f\"transition {i} = ({action}, {obs}, {reward})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Atenção**: Você pode se familiarizar com os argumentos e retorno de ambos os métodos através de seus *docstrings* acessados via `??`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.step?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Agentes \n",
    "\n",
    "A fim de permitir a implementação do **ciclo de interação Agente-Ambiente**, um agente de RL deve ser capaz de escolher uma ação para cada observação recebida do ambiente e aprender (i.e., melhorar sua performance) a partir de suas experiências.\n",
    "\n",
    "Nesse contexto, na classe abstrata `Agent` definimos a interface geral de um agente de RL. \n",
    "\n",
    "> **Atenção**: Familiarize-se com essa classe; todos os agentes definidos nessa aula e nas próximas deverão especializar (i.e., derivar ou sub-classear) essa interface geral."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RLAgent:\n",
    "    \"\"\"\n",
    "    Classe abstrata que define a interface básica de um agente RL.\n",
    "\n",
    "    Args:\n",
    "        obs_space:     especificação do espaço de observações do ambiente.\n",
    "        action_space:  especificação do espaço de ações do ambiente.\n",
    "        config (dict): (opcional) configurações de hiper-parâmetros.\n",
    "    \"\"\"\n",
    "    \n",
    "    __metaclass__ = abc.ABCMeta\n",
    "\n",
    "    def __init__(self, obs_space, action_space, config=None):\n",
    "        self.obs_space = obs_space\n",
    "        self.action_space = action_space\n",
    "        self.config = config\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def act(self, obs):\n",
    "        \"\"\"\n",
    "        Escolhe uma ação para ser tomada dada uma observação do ambiente.\n",
    "        \n",
    "        Args: \n",
    "            obs: observação do ambiente.\n",
    "        \n",
    "        Return:\n",
    "            action: ação válida dentro do espaço de ações.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def observe(self, obs, action, reward, next_obs, done):\n",
    "        \"\"\"\n",
    "        Registra na memória do agente uma transição do ambiente.\n",
    "\n",
    "        Args:\n",
    "            obs:            observação do ambiente antes da execução da ação.\n",
    "            action:         ação escolhida pelo agente.\n",
    "            reward (float): escalar indicando a recompensa obtida após a execução da ação.\n",
    "            next_obs:       nova observação recebida do ambiente após a execução da ação.\n",
    "            done (bool):    True se a nova observação corresponde a um estado terminal, False caso contrário.\n",
    "\n",
    "        Return:\n",
    "            None\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def learn(self):\n",
    "        \"\"\"\n",
    "        Método de treinamento do agente. A partir das experiências de sua memória,\n",
    "        o agente aprende um novo comportamento.\n",
    "\n",
    "        Args: \n",
    "            None\n",
    "\n",
    "        Return:\n",
    "            None\n",
    "        \"\"\"     \n",
    "        raise NotImplementedError\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Definindo um agente aleatório\n",
    "\n",
    "Antes de finalmente definir o ciclo de interação agente-ambiente, vamos implementar um agente que escolhe ações aleatórias.\n",
    "\n",
    "O agente `RandomPolicy` tem seu comportamento definido por uma política estocástica dada por uma distribuição uniforme sobre as ações válidas:\n",
    "\n",
    "$$\n",
    "\\mathbf{a}_t \\sim \\pi(\\cdot|\\mathbf{s}) = \\mathcal{Uniform}(\\{ \\mathbf{a} : \\mathbf{a} \\in \\mathcal{A} \\})~.\n",
    "$$\n",
    "\n",
    "Note que nesse ponto do curso, a implementação do agente aleatório é basicamente ilustrativa. No entanto, como veremos nas aulas seguintes, um agente que implementa uma política aleatória tem duas importantes funções:\n",
    "1. servir de referência de performance final; e\n",
    "2. guiar a inicialização de agentes de RL.\n",
    "\n",
    "Em outras palavras, se um agente de RL após o treinamento não conseguir uma performance significativamente melhor do que aquela do agente aleatório, então muito provavelemente algo não está funcionando como deveria. Além disso, ao garantir que a inicialização de uma política induza um comportamente similar ao de um agente aleatório, não estaremos enviesando a exploração inicial do agente; o que poderia levar muito rapidamente para uma performance sub-ótima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomPolicy(RLAgent):\n",
    "    \"\"\"\n",
    "    Agente aleatório. Escolhe aleatoriamente uma ação independentemente\n",
    "    da observação recebida do ambiente.\n",
    "    \n",
    "    Args:\n",
    "        action_space:  especificação do espaço de ações do ambiente.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, observation_space, action_space, config=None):\n",
    "        super(RandomPolicy, self).__init__(observation_space, action_space, config)\n",
    "\n",
    "    def act(self, obs):\n",
    "        \"\"\"Retorna uma ação aleatória.\"\"\"\n",
    "        return self.action_space.sample()\n",
    "\n",
    "    def observe(self, obs, action, reward, next_obs, done):\n",
    "        \"\"\"Ignora transições; i.e., um agente aletório não armazena experiências na memória.\"\"\"\n",
    "        pass\n",
    "\n",
    "    def learn(self):\n",
    "        \"\"\"Um agente aletório não aprende; i.e., não melhora seu comportamento.\"\"\"\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note que para uma mesma observação o agente `RandomPolicy` retorna diferentes ações a cada chamada:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = RandomPolicy(env.observation_space, env.action_space)\n",
    "\n",
    "obs = env.reset()\n",
    "print([agent.act(obs) for _ in range(20)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_action_distribution(agent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Ciclo de Interação Agente-Ambiente\n",
    "\n",
    "Após entender a API do OpenAI Gym e se familiarizar com a interface geral de um agente de RL, estamos pronto para programar o ciclo de interação Agente-Ambiente.\n",
    "\n",
    "Note que tanto o *treinamento* como a *avaliação de performance* de agentes de RL (baseados em simuladores) dependem da coleta de experiências a fim de estimar uma diferentes grandezas que são necessárias nos algoritmos de RL (e.g., retorno de episódios, gradientes de políticas, ...).\n",
    "\n",
    "Esse é o objetivo principal do ciclo de interação com o ambiente: permitir ao agente explorar o ambiente e coletar dados para seu aprendizado.\n",
    "\n",
    "> **Atenção**: Praticamente todos os pacotes de RL disponíveis implementam uma versão desse loop de interação. Dessa forma, independentemente se seu objetivo é desenvolver sua própria biblioteca de RL ou apenas re-utilizar código pré-existente, é importante entender os principais conceitos envolvidos!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nessa seção testaremos a política aleatória em uma outra versão do ambiente MountainCar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"MountainCarContinuous-v0\")\n",
    "agent = RandomPolicy(env.observation_space, env.action_space)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**<font color=\"red\">EXERCÍCIO-PROGRAMA 1:</font>**\n",
    "\n",
    "Nesse exercício você deverá utilizar os métodos da API do Gym a fim de permitir que um agente de RL simule um episódio. Complete a função `sample_episode` com seu código e preste atenção para retornar as variáveis definidas na documentação. Caso necessário revise a <a href=\"/lab#1.2-Interface-do-Gym:-métodos-reset(),-step()-e-render()\" target=\"_self\">Seção 1.2</a>.\n",
    "\n",
    ">**Atenção**: Para visualizar o episódio não se esqueça de chamar `env.render()` durante a simulação da trajetória. Use a flag `render` em um *if-statement* do Python para dinamicamente habilitar a visualização. Uma vez que a parte gráfica consome muito tempo, é comum desabilitar a renderização do ambiente durante o treinamento e avaliação de um agente de RL. Além disso, chame `env.close()` ao final do ciclo para fechar a janela de simulação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_episode(agent, env, render=False):\n",
    "    \"\"\"\n",
    "    Simula um episódio completo de interação do agente com o ambiente.\n",
    "    \n",
    "    Args:\n",
    "        agent (RLAgent):       agente responsável por retornar ações.\n",
    "        env (gym.Environment): simulador de ambiente do OpenAI Gym.\n",
    "        render (bool):         (opcional) flag para habilitar a renderização do ambiente.\n",
    "        \n",
    "    Return:\n",
    "        (total_reward, episode_length): retorno obtido pelo agente no episódio e\n",
    "        número de passos de decisão realizados no episódio.\n",
    "    \"\"\"\n",
    "    total_reward = 0.0\n",
    "    episode_length = 0\n",
    "\n",
    "    # SEU CÓDIGO AQUI ===================================\n",
    "    \n",
    "    obs = env.reset()\n",
    "    \n",
    "    done = False\n",
    "    while not done:\n",
    "        action = agent.act(obs)\n",
    "        next_obs, reward, done, _ = env.step(action)\n",
    "        \n",
    "        total_reward += reward\n",
    "        episode_lenght += 1\n",
    "        \n",
    "        if render:\n",
    "            env.render()\n",
    "        \n",
    "        obs = next_obs\n",
    "        \n",
    "    env.close()\n",
    "    # ===================================================\n",
    "\n",
    "    return total_reward, episode_length\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute o código abaixo para testar a sua implementação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_reward, episode_length = sample_episode(agent, env, render=True)\n",
    "print(f\"return = {total_reward:.4f}, passos de decisão = {episode_length}\\r\", end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A menos que você tenha tido sorte na simulação, você deve ter observado que o carro nunca chega próximo à linha de chegada. :(\n",
    "\n",
    "Não se preocupe vamos resolver isso nas próximas aulas!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma vez implementado a função `sample_episode` você pode amostrar diferentes trajetórias com a função `run` definida abaixo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(agent, env, num_episodes):\n",
    "    episode_returns, episode_lengths = [], []\n",
    "\n",
    "    for episode in range(num_episodes):\n",
    "        total_reward, episode_length = sample_episode(agent, env)\n",
    "    \n",
    "        episode_returns.append(total_reward)\n",
    "        episode_lengths.append(episode_length)\n",
    "\n",
    "        if episode % 10 == 0:\n",
    "            print(f\"episode = {episode}, return = {total_reward:.4f}, length = {episode_length}\\r\", end=\"\")\n",
    "\n",
    "    return episode_returns, episode_lengths\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute o código abaixo para simular `NUM_EPISODES` trajetórias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPISODES = 200\n",
    "\n",
    "episode_returns, episode_lengths = run(agent, env, NUM_EPISODES)\n",
    "\n",
    "plot_episode_total_rewards(episode_returns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Atenção**: se você obteve um pico de retorno com um valor positivo (i.e., *outlier*), execute novamente a simulação. Caso contrário, você deve ter obtido um retorno médio (vide linha vermelha) entre -34 e -33 para `NUM_EPISODES==200`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**<font color=\"red\">QUESTÕES:</font>**\n",
    "\n",
    "1. Qual a diferença entre o ambiente `MountainCar-v0` utilizado como exemplo na <a href=\"/lab#1.-Ambientes-no-OpenAI-Gym\" target=\"_self\">Seção 1</a> e o ambiente `MountainCarContinuous-v0` que você acabou de simular?\n",
    "2. Como você interpreta os gráficos acima `Episode Return` e `Episode Return (Histogram)` ? Como você explicaria essas variações ruidosas da recompensa total?\n",
    "3. Se você executar a simulação várias vezes, obterá resultados ligeiramente diferentes? Ao que se deve essa incerteza nos resultados?\n",
    "4. Você diria que o agente aleatório obteve uma boa performance? *Dica*: relacione os resultados obtidos com a especificação do ambiente `MountainCarContinuous-v0` (e.g., `env.spec`).\n",
    "5. Note que durante a simulação o `Episode Length` se manteve constante ao longo dos episódios. O que isso significa do ponto de vista da tarefa de RL?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
